
<!DOCTYPE html>

<html lang="english">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Fusing Operations &#8212; MiniTorch 0.3 documentation</title>
    
    <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" href="_static/styles/pydata-sphinx-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    
    <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="GPU Programming" href="cuda.html" />
    <link rel="prev" title="Parallel Computation" href="parallel.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="english">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="index.html">
  <img src="_static/minitorch.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="setup.html">
  Setup
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="mlprimer.html">
  ML Primer
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module0.html">
  Fundamentals
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module1.html">
  Autodiff
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module2.html">
  Tensors
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="module3.html">
  Efficiency
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module4.html">
  Networks
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/minitorch/" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/srush_nlp" rel="noopener" target="_blank" title="Twitter"><span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p>
 <span class="caption-text">
  Guides
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="parallel.html">
   Parallel Computation
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Fusing Operations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cuda.html">
   GPU Programming
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-matrix-multiplication">
   Example: Matrix Multiplication
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="fusing-operations">
<h1>Fusing Operations<a class="headerlink" href="#fusing-operations" title="Permalink to this headline">¶</a></h1>
<p>Another approach we can use to help improve tensor computations is to
specialize commonly used combinations of operators. Combining operations
can eliminate unnecessary
intermediate tensors. This is particularly helpful for saving memory.</p>
<p>There is a lot of ongoing work on how to do this operator fusion
automatically. However, for very common operators. it is worth just
writing these operators directly and speeding them up.</p>
<p>In minitorch we will do this fusion by customizing special operations. If we
find it useful, we will add these operations in Numba.</p>
<section id="example-matrix-multiplication">
<h2>Example: Matrix Multiplication<a class="headerlink" href="#example-matrix-multiplication" title="Permalink to this headline">¶</a></h2>
<p>Let's consider a matrix multiplication example.  In past modules we
have done matrix multiplication by applying a broadcasted <cite>zip</cite> and
then a <cite>reduce</cite>. For example, consider a tensor of size (2, 3, 1) and
a tensor of size (3, 2). We first zip these together with broadcasting
to produce a tensor of size (2, 3, 2):</p>
<img alt="_images/matmul3d1.png" class="align-center" src="_images/matmul3d1.png" />
<p>And then reduce it to a tensor of size (2, 1, 2), which we can view as (2, 2):</p>
<img alt="_images/matmul3d2.png" class="align-center" src="_images/matmul3d2.png" />
<p>This computation is correct, but it has two issues.  First, it needs
to create a tensor of size (2, 3, 2) in the intermediate step. These
tensor can be an order of magnitude larger than either of the tensors
that were passed in. Another more subtle problem is that the <cite>reduce</cite>
operator may need to call <cite>save_for_backwards</cite> on this tensor, which
means it stays in memory throughout all of our forward computations.</p>
<p>An alternative option is to fuse together these two operations. We
will create a single matmul operations using python <cite>&#64;</cite> operator. We
can then skip computing the intermediate value and directly compute
the output. We can do this by writing a specialized tensor <cite>Function</cite>
with a <cite>forward</cite> function that directly produces the output and a
<cite>backward</cite> that produces the required gradient.</p>
<img alt="_images/matmulsimple.png" class="align-center" src="_images/matmulsimple.png" />
<p>This allows us to specialize our implementation of matrix
multiplication. We do this by 1) walking over the output indices, 2)
seeing which indices are reduced, and 3) then seeing which were part
of the zip. Here's what that looks like in our diagram.</p>
<img alt="_images/matmul1.png" class="align-center" src="_images/matmul1.png" />
<p>Given how important this operator is, it is worth spending the time to
think about how to make each of these steps fast. Once we know the
output index we can very efficiently walk through the input indices
and accumulate their sums.</p>
<p>A fast matrix multiplication operator can be used to compute the
<cite>forward</cite>.  To compute backward we need to reverse the operations that
we computed. In particular this requires zipping grad out with the
alternative input matrix. We can see the <cite>backward</cite> step by tracing
the forward arrows:</p>
<img alt="_images/matmul back.png" class="align-center" src="_images/matmul back.png" />
<p>It would be a bit annoying to optimize this code as well, but again
luckily, to compute the <cite>backward</cite> step , we can reuse our forward
optimization.  In fact we can simply use the following identity from
matrix calculus that tells use backward can be computed as a transpose
and another matrix multiply.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray*}
f(M, N) &amp;=&amp;  M N \\
g'_M(f(M, N)) &amp;=&amp;  grad_{out} N^T \\
g'_N(f(M, N)) &amp;=&amp;  M^T grad_{out}
\end{eqnarray*}\end{split}\]</div>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="parallel.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Parallel Computation</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="cuda.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">GPU Programming</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, Sasha Rush.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>