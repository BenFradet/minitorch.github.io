========================
Pooling
========================


In past assignments we have found it useful to reduce over dimensions
to reduce the shape of tensors. For example, in the NLP example, we
sum over the length of the sentence in order to classify based on the
word representations. Critically this does not remove the importance
of words, (they still all receive gradient information), but it does
allow us to make a single classification decision based on a fixed sized
representation.


This style of network goes by the informal name `pooling` in the
neural network literature. When we reduce part of our input to work
with a smaller size, we say we have pooled together the
representations. Using reduction over length or other dimensions
is one form of pooling, in the case of a sequences, we might call this
X-over-time pooling (where X might be a sum / mean / max / etc.) :

.. image:: figs/Conv/pool1.png
           :align: center
           :width: 500px


Another common form of pooling is to only pool locally within a
dimension. For instance we might pool together neighboring position to
reduce the total length by a factor of 2. This is common in domains
like speech recognition with the input sequences are very long.

.. image:: figs/Conv/pool2.png
           :align: center
           :width: 500px


To avoid implementing this as a loop, we can manipulate the shape and
strides of a tensor to pool it directly. Assuming we have a contiguous
starting tensor, we can simply view the tensor to add an extra dimension.
For instance instead of (8,) we view this as a (4, 2) tensor.

.. image:: figs/Conv/pool3.png
           :align: center
           :width: 500px

Once we have it in this form we can reduce over the second dimension
to create a (4,1) tensor, which can be viewed as a (4,). As long as we
ensure that our dimensions are divisible by our pooling constant this
will produce the correct result. If not we can just pad our starting
tensors, or add padding along the way. Here is the full process.

.. image:: figs/Conv/pool4.png
           :align: center
           :width: 500px

For the homework, we will have you implement as version of this
pooling in two-dimensions for images. These functions will require you
to generalize the idea in 1D pooling to create a shape with two extra
dimesions to reduce over.

.. image:: figs/Conv/pool2d.png
           :align: center
           :width: 500px


The benefit of this approach is that applying a small convolution over the output
covers a larger area of the original image. Parameters in these later layers will
represent higher-level properties of the image.
