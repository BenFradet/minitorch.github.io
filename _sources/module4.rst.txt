========================
Module 4 - Networks
========================
.. image:: figs/mnist/orig.png
           :width: 400px
           :align: center
.. image:: figs/mnist/mnist2.png
           :width: 400px
           :align: center

.. image:: figs/mnist/mnist5.png
           :width: 400px
           :align: center

.. image:: figs/mnist/mnist4.png
           :width: 400px
           :align: center

We now have a fully working deep learning library with most of the
features of a real industrial system like Torch. To take advantage of
this hard work this section is entirely based around using the
software to build an image recognition system. In particular we will
build the infrastructure for a version of LeNet on MNist a classic
convolutional neural network for digit recognition.


All starter code is available in https://github.com/minitorch/Module-4 .

To begin, remember to first activate your virtual environment.

>>> source venv/bin/activate

And then clone your assignment.

>>> git clone {{STUDENT_ASSIGNMENT4_URL}}
>>> cd Module-4
>>> pip install -Ue .

You will also need the files so be sure to pull them over
to your new repo.

Be sure to continue to follow the :doc:`contributing` guidelines.

.. image:: figs/Conv/networkcnn.png
           :align: center


.. toctree::
   :maxdepth: 3
   :glob:
   :caption: Guides

   convolution
   pooling
   softmax

Tasks
********

Task 4.1: Convolution
==================================

.. note:: This task requires basic familiarity with convolution.
   Be sure to read the section on :doc:`convolution`.

.. todo::
   Complete the following function in `minitorch/nn.py` and pass tests marked
   as `task4_1`.



Task 4.2: Pooling
==================================

.. note:: This task requires basic familiarity with pooling as a concept.
   Be sure to read the section on :doc:`pooling`.

.. todo::
   Complete the following functions in `minitorch/nn.py` and pass tests
   marked as `task4_2`.

.. autofunction:: minitorch.tile
.. autofunction:: minitorch.avgpool2d
.. autofunction:: minitorch.maxpool2d

Task 4.3: Max, Argmax, Softmax
===============================

.. todo::
   Return to  `minitorch/tensor.py` and add a max reduction function.
   Add 2 property tests for the function and ensure that you understand its
   gradient computation.
   Mark the tests as `task4_3`.

.. autofunction:: minitorch.max
.. autofunction:: minitorch.argmax
.. autofunction:: minitorch.softmax
.. autofunction:: minitorch.logsoftmax


Task 4.4: Modules
==================================

.. todo::
   Complete the following function in `minitorch/nn.py` and pass tests marked
   as `task4_4`.

.. autofunction:: minitorch.dropout



Task 4.5: Training a Classifier
==================================



If your code works, you should now be able to move on to the tensor
training script in `project/run_fast_tensor.py`.  This code is the same
basic training setup as  :doc:`module2`, but now utilizes your fast tensor
code. We have left the `matmul` layer blank for you to implement with
your tensor code.



.. todo::
   * Implement the missing functions in `project/run_fast_tensor.py`. These
     should
     do exactly the same thing as the corresponding functions in
     `project/run_tensor.py`,
     but now use the faster backend


   * Train a tensor model and add your results for all dataset
     to the README.

   * Run a bigger model and record the time per epoch reported by the
     trainer. Here is the command ::

      python run_mnist_multiclass.py

     On a standard Colab GPU setup, aim for you CPU to get below 2 seconds per epoch and
     GPU to be below 1 second per epoch. (With some cleverness you can do much better.)
