# + slideshow={"slide_type": "skip"}
from mt_diagrams.drawing import connect
from mt_diagrams.tensor_draw import color, draw_equation, matrix, matrix_op, t, image_matmul_full, image_matmul_simple, m
import chalk
chalk.set_svg_draw_height(400)
chalk.set_svg_height(200)
import numba
import minitorch
FastTensorBackend = minitorch.TensorBackend(minitorch.FastOps)
def tensor(x):
    return minitorch.tensor(x, backend=FastTensorBackend)

def rand(*shape):
    return minitorch.rand(shape, backend=FastTensorBackend)

# + [markdown] slideshow={"slide_type": "slide"}
# Module 4.0 - Networks
# ===================================

# + [markdown] slideshow={"slide_type": "slide"}
# Fusion
# -------
# * Optimization across operator boundary
# * Save speed or memory in by avoiding extra forward/backward
# * Can open even great optimization gains

# + [markdown] slideshow={"slide_type": "slide"}
# Simple Matmul Pseudocode
# -------------------------
#
# ```python
# for outer_index in out.indices():
#   for inner_val in range(J):
#        out[outer_index] += A[outer_index[0], inner_val] * \
#                            B[inner_val, outer_index[1]]
# ```


# + [markdown] slideshow={"slide_type": "slide"}
# Compare to zip / reduce
# -----------------------

# Code 

# ```python
#   ZIP STEP
#   C = zeros(broadcast_shape(A.view(I, J, 1), B.view(1, J, K)))
#   for C_outer in C.indices():
#       C[C_out] = A[outer_index[0], inner_val] * \
#                  B[inner_val, outer_index[1]]
#   REDUCE STEP
#   for outer_index in out.indices():
#      for inner_val in range(J):
#         out[outer_index] = C[outer_index[0], inner_val,
#                              outer_index[1]]
# ```


# + [markdown] slideshow={"slide_type": "slide"}
# Diagram
# ---------

# Large Square

# ![](https://www.es.ele.tue.nl/~mwijtvliet/5KK73/pages/mmcuda_files/GPU_tiling.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Basic CUDA - Square Large
# --------------------------

# Basic CUDA ::

# + slideshow={"slide_type": "x"}
def mm_shared1(out, a, b, K):
    ...
    for s in range(0, K, TPB):
        sharedA[local_i, local_j] = a[i, s + local_j]
        sharedB[local_i, local_j] = b[s + local_i, j]
        ...
        for k in range(TPB):
            t += sharedA[local_i, k] * sharedB[k, local_j]
    out[i, j] = t


# + [markdown] slideshow={"slide_type": "slide"}
# Non-Square - Dependencies
# -----------------------------

# ![](https://upload.wikimedia.org/wikipedia/commons/1/11/Matrix_multiplication_diagram.svg)


# + [markdown] slideshow={"slide_type": "slide"}
# Challenges
# ------------

# * How do you handle the different size of the matrix?

# * How does this interact with the block size?

# + [markdown] slideshow={"slide_type": "slide"}
# Quiz
# -----
# Quiz


# + [markdown] slideshow={"slide_type": "slide"}
# Today's Class
# ----------------
# * Architecture
# * Memory
# * Communication

# + [markdown] slideshow={"slide_type": "slide"}

# Goal: AI Tasks
# -------------------------
# * Sentiment Analysis
# * Image Recognition


# + [markdown] slideshow={"slide_type": "slide"}
# Natural Language Processing
# ----------------------------

# * Systems for human language
# * Broad area of study with lots of challenges
# * Heavily uses ML, more in recent years


# + [markdown] slideshow={"slide_type": "slide"}
# Sentiment Classification
# -------------------------
# * Canonical sentence classification problem
# * Given sentence predict sentiment class
# * Key aspects: word polarity

# + [markdown] slideshow={"slide_type": "slide"}
# Data
# ------

# ![](https://minitorch.github.io/figs/NLP/negative.png)
#
# ![](https://minitorch.github.io/figs/NLP/positive.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Image Recognition
# ----------------------------
# * Classical problem in intro machine learning.


# + [markdown] slideshow={"slide_type": "slide"}
# Data Set
# -------------
# ![](http://minitorch.github.io/figs/Conv/mnist.png)


# + [markdown] slideshow={"slide_type": "slide"}
# Data Labels
# ------------
# ![](http://minitorch.github.io/figs/Conv/im1.png)
# ![](http://minitorch.github.io/figs/Conv/im2.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Data Points
# ------------
# ![](http://minitorch.github.io/figs/Graphs/data1.png)
#
# ![](http://minitorch.github.io/figs/Graphs/data2.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Strategy
# ---------
# Build a neural network to classify these

# ![](http://minitorch.github.io/figs/Conv/im1.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Problem Setup
# ---------------

# * Training: Exactly the same as simple
# * Loss: Exactly the same as simple
# * Models: Mostly similar to the simple problem.

# + [markdown] slideshow={"slide_type": "slide"}
# Challenges
# ------------------
# 1) How do we handle input features?
# 2) How do we look at variable-size areas?
# 3) How do we predict multiple labels?

# + [markdown] slideshow={"slide_type": "slide"}
# Basic NLP
# ===========


# + [markdown] slideshow={"slide_type": "slide"}
# Network Challenges
# --------------------
# * Converting words to tensors
# * Converting sentences to tensors
# * Handling word combinations

# + [markdown] slideshow={"slide_type": "slide"}
# What is a word?
# ----------------
# * Treat words as index in vocabulary
# * Represent as a one-hot vector

# + [markdown] slideshow={"slide_type": "slide"}
# Vector Form
# ------------------------
# ![](https://minitorch.github.io/figs/NLP/onehot.png)


# + [markdown] slideshow={"slide_type": "slide"}
# One-Hot Issue
# --------------
# * Tens of thousands of words
# * Opposite problem as before, 2-features to 10,000
# * ``Embedding'' represent high-dim space in low dim

# + [markdown] slideshow={"slide_type": "slide"}
# Embedding Table
# ------------------------
# ![](https://minitorch.github.io/figs/NLP/embweight.png)


# + [markdown] slideshow={"slide_type": "slide"}
# Intuition: Lookup in Table
# ---------------------------

# Get word vector
# +  slideshow={"slide_type": "x"}

VOCAB = 1000
EMB = 100
embeddings = rand(EMB, VOCAB)
word = 20
embeddings[0, word]


# * Challenge:  How to compute `backward`

# + [markdown] slideshow={"slide_type": "slide"}
# Alternative: Lookup by broadcast
# ------------------------------------

# Get word vector

# +  slideshow={"slide_type": "x"}
word_one_hot = tensor([0 if i != word else 1
                       for i in range(VOCAB)])
embeddings @ word_one_hot.view(VOCAB, 1)


# + [markdown] slideshow={"slide_type": "slide"}
# Embedding One
# ------------------------
# ![](https://minitorch.github.io/figs/NLP/embone.png)

# + [markdown] slideshow={"slide_type": "slide"}
# How does this share information?
# ---------------------------------
#
# * Similar words have similar embedding dim
# * Dot-product - easy way to tell similarity

# ```
# (word_emb1 * word_emb2).sum()
# ```

# * Differentiable!

# + [markdown] slideshow={"slide_type": "slide"}
# Embedding Layer
# ----------------

# Easy to write as a layer

# + slideshow={"slide_type": "x"}
class Embedding(minitorch.Module):
    def __init__(self, vocab_size, emb_size):
        super().__init__()
        self.weights = \
            minitorch.Parameter(minitorch.rand((vocab_size, emb_size)))
        self.vocab_size = vocab_size

    def forward(input):
        return (input @ self.weights.values)


# + [markdown] slideshow={"slide_type": "slide"}
# Where do these come from?
# --------------------------

# * Trained from a different model
# * Extracted and posted to use
# * (Many more details in NLP class)

# + [markdown] slideshow={"slide_type": "slide"}
# Examples
# -----------

# Embeddings

#   ```python
#    embedding.weights.value.update(pretrained_weights)
#   ```

# * https://projector.tensorflow.org/

# + [markdown] slideshow={"slide_type": "slide"}
# Examples
# -----------

# Query 1 
# ```
#    ^(lisbon|portugal|america|washington|rome|athens|london|england|greece|italy)$
# ```

# Query 2 
# ```
#   ^(doctor|patient|lawyer|client|clerk|customer|author|reader)$
# ```


# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 2: Sentence Length
# -----------------------------
# * Examples may be of different length
# * Need to all be converted to vectors and utilized

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge: Length Dimension
# ------------------------------
# ![](https://minitorch.github.io/figs/NLP/senthot.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Value Transformation
# ---------------------

# * batch x length x vocab
# * batch x length x feature
# * batch x feature
# * batch x hidden
# * batch

# + [markdown] slideshow={"slide_type": "slide"}
# Network
# ------------------------
# ![](https://minitorch.github.io/figs/NLP/sentemb.png)


# + [markdown] slideshow={"slide_type": "slide"}
# Reduction / "Pooling"
# ------------------------
# ![](https://minitorch.github.io/figs/NLP/pooling.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Benefits
# ----------

# * Extremely simple
# * Embeddings encode key information
# * Have all the tools we need

# + [markdown] slideshow={"slide_type": "slide"}
# Full Model
# ------------------------

# ![](https://minitorch.github.io/figs/NLP/full.png)


# + [markdown] slideshow={"slide_type": "slide"}
# Issues
# ------
# * Completely ignores relative order
# * Completley ignores absolute order
# * Embeddings for all words, even rare ones


# + [markdown] slideshow={"slide_type": "slide"}
# Basic Recognition
# =================

# Challenges
# ------------
# * Converting images to tensors
# * Handling different scales
# * Multiclass prediction.

# + [markdown] slideshow={"slide_type": "slide"}
# Network
# -------------
# ![](https://minitorch.github.io/figs/Conv/networkcnn.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 1: Input Representation
# ----------------------------------

# [link](https://colab.research.google.com/drive/18pfkiPBLS-IOTMng-umraXnGE7IX6pWE?usp=sharing)

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 1: Input Representation
# ----------------------------------


# ![](https://minitorch.github.io/figs/mnist.png)
#           

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 1: Input Features
# ----------------------------

# ![](https://minitorch.github.io/figs/Conv/conv.png)


# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 1: Input Features
# ----------------------------

# ![](https://minitorch.github.io/figs/Conv/conv2.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 1: Input Representation
# ----------------------------------

# ![](https://minitorch.github.io/figs/mnistregion.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 2: Variable Size Area
# ---------------------------------

# ![](https://minitorch.github.io/figs/Conv/pool2d.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 2: Variable Size Area
# ---------------------------------
# ![](https://minitorch.github.io/figs/Conv/pool2d.png)
#           

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 2: MNist Zoom
# ---------------------------------
# ![](https://minitorch.github.io/figs/mnistzoom.png)
#          

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 3: Multiple Output
# ---------------------------------

# ![](https://minitorch.github.io/figs/Conv/value.png)

# ![](https://minitorch.github.io/figs/Conv/softmax.png)
#          

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge 3: Multiple Output
# ---------------------------------

# ![](https://minitorch.github.io/figs/hist.png)


# + [markdown] slideshow={"slide_type": "slide"}
# Q&A
# ----
