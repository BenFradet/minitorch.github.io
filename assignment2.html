

<!DOCTYPE html>
<html class="writer-html5" lang="english" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Assignment &mdash; MiniTorch 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MiniTorch
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="setup.html">Workspace Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="module0.html">Module 0 - Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="module1.html">Module 1 - Auto-Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="module2.html">Module 2 - Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="module3.html">Module 3 - Efficiency</a></li>
<li class="toctree-l1"><a class="reference internal" href="module4.html">Module 4 - Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlprimer.html">ML Primer</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MiniTorch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Assignment</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/assignment2.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="assignment">
<h1>Assignment<a class="headerlink" href="#assignment" title="Permalink to this headline">¶</a></h1>
<div class="section" id="tasks-2-1-tensor-data-indexing">
<h2>Tasks 2.1: Tensor Data - Indexing<a class="headerlink" href="#tasks-2-1-tensor-data-indexing" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires familiarity with tensor indexing.
Be sure to first carefully read the section on
<a class="reference internal" href="tensordata.html"><span class="doc">Tensors</span></a>. You may also find it helpful to read
the tutorials for using tensors/arrays in Torch or Numpy.</p>
</div>
<p>The MiniTorch library implements the core multidimensional tensor backend as
<code class="xref py py-class docutils literal notranslate"><span class="pre">minitorch.TensorData</span></code>. This is class handles indexing, storage, transposition,
and low-level details such as strides. Before turning to the user-facing class <code class="xref py py-class docutils literal notranslate"><span class="pre">minitorch.Tensor</span></code>,
first implement these core functions.</p>
<div class="admonition-todo admonition" id="id1">
<p class="admonition-title">Todo</p>
<p>Add calls in <cite>minitorch/tensor_data.py</cite> for each of the following, and pass tests marked as <cite>task2_1</cite>.</p>
</div>
<dl class="py function">
<dt id="minitorch.index_to_position">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">index_to_position</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.index_to_position" title="Permalink to this definition">¶</a></dt>
<dd><p>Unmaterialized device function</p>
</dd></dl>

<dl class="py function">
<dt id="minitorch.count">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">count</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.count" title="Permalink to this definition">¶</a></dt>
<dd><p>Unmaterialized device function</p>
</dd></dl>

<dl class="py function">
<dt id="minitorch.TensorData.permute">
<code class="sig-prename descclassname">minitorch.TensorData.</code><code class="sig-name descname">permute</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">self</span></em>, <em class="sig-param"><span class="o">*</span><span class="n">order</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.TensorData.permute" title="Permalink to this definition">¶</a></dt>
<dd><p>Permute the dimensions of the tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>order</strong> (<em>list</em>) -- a permutation of the dimensions</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a new TensorData with the same storage and a new dimension order.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">TensorData</span></code></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="tasks-2-2-tensor-operations">
<h2>Tasks 2.2: Tensor Operations<a class="headerlink" href="#tasks-2-2-tensor-operations" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires familiarity with higher-order tensor operations.
Be sure to first carefully read the section on
<a class="reference internal" href="tensorops.html"><span class="doc">Operations</span></a>. You may also find it helpful to go back to
Module 0 and make sure you understand higher-order functions and currying.</p>
</div>
<p>The tensor operations will to apply high-level, higher-order
operations to all values in a tensor simultaneously. In particularly
allowing you to map, zip, and reduce tensor data objects together. On
top of this foundation we can build up a similar class to the Tensor functions
just like we did for the scalar functions. In this task you should first implement
the generic tensor ops and then use these to provide the <cite>forward</cite> functions
for tensors.</p>
<span class="target" id="module-minitorch.tensor_ops"></span><div class="admonition-todo admonition" id="id2">
<p class="admonition-title">Todo</p>
<p>Add functions in <cite>minitorch/tensor_ops.py</cite> and <cite>minitorch/tensor.py</cite> for each of the following, and pass tests marked as <cite>task2_2</cite>.</p>
</div>
<dl class="py function">
<dt id="minitorch.tensor_map">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">tensor_map</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fn</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.tensor_map" title="Permalink to this definition">¶</a></dt>
<dd><p>Higher-order tensor map function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fn</strong> -- function mappings floats-to-floats to apply.</p></li>
<li><p><strong>out</strong> (<em>array</em>) -- storage for out tensor.</p></li>
<li><p><strong>out_shape</strong> (<em>array</em>) -- shape for out tensor.</p></li>
<li><p><strong>out_strides</strong> (<em>array</em>) -- strides for out tensor.</p></li>
<li><p><strong>out_size</strong> (<em>int</em>) -- size of out</p></li>
<li><p><strong>in_storage</strong> (<em>array</em>) -- storage for in tensor.</p></li>
<li><p><strong>in_shape</strong> (<em>array</em>) -- shape for in tensor.</p></li>
<li><p><strong>in_strides</strong> (<em>array</em>) -- strides for in tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="minitorch.tensor_zip">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">tensor_zip</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fn</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.tensor_zip" title="Permalink to this definition">¶</a></dt>
<dd><p>Higher-order tensor zipWith (or map2) function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fn</strong> -- function mappings two floats to float to apply.</p></li>
<li><p><strong>out</strong> (<em>array</em>) -- storage for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_shape</strong> (<em>array</em>) -- shape for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_strides</strong> (<em>array</em>) -- strides for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_size</strong> (<em>int</em>) -- size of <cite>out</cite>  tensor</p></li>
<li><p><strong>a_storage</strong> (<em>array</em>) -- storage for <cite>a</cite> tensor.</p></li>
<li><p><strong>a_shape</strong> (<em>array</em>) -- shape for <cite>a</cite> tensor.</p></li>
<li><p><strong>a_strides</strong> (<em>array</em>) -- strides for <cite>a</cite> tensor.</p></li>
<li><p><strong>b_storage</strong> (<em>array</em>) -- storage for <cite>b</cite> tensor.</p></li>
<li><p><strong>b_shape</strong> (<em>array</em>) -- shape for <cite>b</cite> tensor.</p></li>
<li><p><strong>b_strides</strong> (<em>array</em>) -- strides for <cite>b</cite> tensor.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="minitorch.tensor_reduce">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">tensor_reduce</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fn</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.tensor_reduce" title="Permalink to this definition">¶</a></dt>
<dd><p>Higher-order tensor reduce function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fn</strong> -- function mapping two floats to float for combine.</p></li>
<li><p><strong>out</strong> (<em>array</em>) -- storage for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_shape</strong> (<em>array</em>) -- shape for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_strides</strong> (<em>array</em>) -- strides for <cite>out</cite> tensor.</p></li>
<li><p><strong>out_size</strong> (<em>int</em>) -- size of <cite>out</cite> tensor</p></li>
<li><p><strong>a_storage</strong> (<em>array</em>) -- storage for <cite>a</cite> tensor.</p></li>
<li><p><strong>a_shape</strong> (<em>array</em>) -- shape for <cite>a</cite> tensor.</p></li>
<li><p><strong>a_strides</strong> (<em>array</em>) -- strides for <cite>a</cite> tensor.</p></li>
<li><p><strong>reduce_shape</strong> (<em>array</em>) -- shape of reduction (1 for dimension kept, shape value for dimensions summed out)</p></li>
<li><p><strong>reduce_size</strong> (<em>int</em>) -- size of reduce shape</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="tasks-2-3-gradients-and-autograd">
<h2>Tasks 2.3: Gradients and Autograd<a class="headerlink" href="#tasks-2-3-gradients-and-autograd" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires familiarity with tensor backward operations.
Be sure to first carefully read the section on
<a class="reference internal" href="tensor.html"><span class="doc">Tensor Variables</span></a>. You may also find it helpful to go back to
Module 1 and review <cite>variables</cite> and <cite>functions</cite>.</p>
</div>
<p>Just as with <a class="reference internal" href="scalar.html#minitorch.Scalar" title="minitorch.Scalar"><code class="xref py py-class docutils literal notranslate"><span class="pre">minitorch.Scalar</span></code></a>, the <code class="xref py py-class docutils literal notranslate"><span class="pre">minitorch.Tensor</span></code>
is a Variable that support automatic differentiation. In this task you
will need to implement each of the backward functions and ensure that
they pass the tests.</p>
<div class="admonition-todo admonition" id="id3">
<p class="admonition-title">Todo</p>
<p>Add backward functions <cite>minitorch/tensor_ops.py</cite> for each of the following, and pass tests marked as <cite>task2_3</cite>.</p>
</div>
</div>
<div class="section" id="tasks-4-tensor-broadcasting">
<h2>Tasks 4: Tensor Broadcasting<a class="headerlink" href="#tasks-4-tensor-broadcasting" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This task requires familiarity with tensor broadcasting.  Be
sure to first carefully read the section on
<a class="reference internal" href="broadcasting.html"><span class="doc">Broadcasting</span></a>. You may also find it helpful to go through
some of the tutorials of Torch or Numpy broadcasting as it is
identical.</p>
</div>
<div class="admonition-todo admonition" id="id4">
<p class="admonition-title">Todo</p>
<p>Add broadcasing functions to <cite>minitorch/tensor_data.py</cite> and <cite>minitorch/tensor_ops.py</cite> for each of the following, and pass tests marked as <cite>task2_4</cite>.</p>
</div>
<dl class="py function">
<dt id="minitorch.shape_broadcast">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">shape_broadcast</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">shape1</span></em>, <em class="sig-param"><span class="n">shape2</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.shape_broadcast" title="Permalink to this definition">¶</a></dt>
<dd><p>Broadcast two shapes to create a new union shape.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape1</strong> (<em>tuple</em>) -- first shape</p></li>
<li><p><strong>shape2</strong> (<em>tuple</em>) -- second shape</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>broadcasted shape</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="tasks-5-training">
<h2>Tasks 5: Training<a class="headerlink" href="#tasks-5-training" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Read project <cite>tensor</cite></p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Sasha Rush

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>