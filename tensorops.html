
<!DOCTYPE html>

<html lang="english">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Operations &#8212; MiniTorch 0.1 documentation</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Tensor Variables" href="tensor.html" />
    <link rel="prev" title="Broadcasting" href="broadcasting.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="index.html">
  <img src="_static/minitorch.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="setup.html">
  Setup
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="mlprimer.html">
  ML Primer
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module0.html">
  Fundamentals
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module1.html">
  Autodiff
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="module2.html">
  Tensors
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module3.html">
  Efficiency
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module4.html">
  Networks
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/minitorch/" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/srush_nlp" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p class="caption">
 <span class="caption-text">
  Guides
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="tensordata.html">
   Tensors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="broadcasting.html">
   Broadcasting
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Operations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tensor.html">
   Tensor Variables
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#core-operations">
   Core Operations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reductions">
   Reductions
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="section" id="operations">
<h1>Operations<a class="headerlink" href="#operations" title="Permalink to this headline">¶</a></h1>
<div class="jupyter_cell docutils container">
<div class="cell_output docutils container">
</div>
</div>
<p>Now we would like to reimplement all
our mathematical operations on tensors.
The goal is to make this feel
simple and intuitive to users of the library. We can break
these operations down as unary transformations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># a) Return a new tensor with the same shape as `tensor_a` where</span>
<span class="c1"># each position is the log/exp/negative of the position in `tensor_a`</span>
<span class="n">tensor_a</span><span class="o">.</span><span class="n">log</span><span class="p">()</span>
<span class="n">tensor_a</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
<span class="o">-</span><span class="n">tensor_a</span>
<span class="o">...</span>
</pre></div>
</div>
<p>Binary transformations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># b) Return a new tensor where each position</span>
<span class="c1"># is the sum/mul/sub of the position in `tensor_a` and</span>
<span class="c1"># `tensor_b`</span>
<span class="n">tensor_a</span> <span class="o">+</span> <span class="n">tensor_b</span>
<span class="n">tensor_a</span> <span class="o">*</span> <span class="n">tensor_b</span>
<span class="n">tensor_a</span> <span class="o">-</span> <span class="n">tensor_b</span>
<span class="o">...</span>
</pre></div>
</div>
<p>And reductions:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># c) Return a new tensor where dim-1 is size 1 and represents</span>
<span class="c1"># the sum/mean over dim-1 in `tensor_a`</span>
<span class="n">tensor_a</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tensor_a</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="o">...</span>
</pre></div>
</div>
<div class="section" id="core-operations">
<h2>Core Operations<a class="headerlink" href="#core-operations" title="Permalink to this headline">¶</a></h2>
<p>We could implement each of these operations individually, but we can
also be a bit lazy and note the structural similarities. If we squint,
these operations look very much like the higher-order functions that
we implemented in <a class="reference internal" href="module0.html"><span class="doc">Fundamentals</span></a>:</p>
<ul class="simple">
<li><p>Operation a / map: These operations just touch each of the
positions in the tensor individually. They don't need to deal with
other positions or know anything about the shape or size of the tensor.
We can view these operations as applying the following transformation:</p></li>
</ul>
<img alt="_images/map.png" class="align-center" src="_images/map.png" />
<ul class="simple">
<li><p>Operation b / zip: These operations only need to pair operations between
input tensors. If we assume the tensors have the same size and shape,
this type of operation simply aligns these two tensors and applies an
operator
to each pair of elements:</p></li>
</ul>
<img alt="_images/zip.png" class="align-center" src="_images/zip.png" />
<ul class="simple">
<li><p>Operation c / reduce: These operations need to group together cells within
a single tensor.
We can think of there being an implied <cite>reduce</cite> shape that is eliminated
in the process of the
output construction. For instance, in the example below, we start with an
input of shape (3, 2) and create
an output of shape (1, 2). Implicitly, we reduce over a ternsor of shape
(3, 1) for each element in the output.</p></li>
</ul>
<img alt="_images/reduce.png" class="align-center" src="_images/reduce.png" />
</div>
<div class="section" id="reductions">
<h2>Reductions<a class="headerlink" href="#reductions" title="Permalink to this headline">¶</a></h2>
<p>Reduction is a bit more complex than the others, so lets discuss how it
is implemented.</p>
<p>Reductions can specify an dimension (or axis) that tells us which elements
to reduce. The
reduction is then applied along that dimension. For example if we <cite>reduce</cite>
dimension 0 we get the
following reduction.</p>
<img alt="_images/sum0.png" class="align-center" src="_images/sum0.png" />
<p>This reduction changes our shape from (3, 2) to (1, 2), i.e. <cite>reducing</cite> the
size of 0-dim. Another way you can view this is as 2 parallel operations,
both of which apply a Module-0 style reduce along the 0-dim. We can look at
the reduction shape of this procedure (3, 1).</p>
<p>Applying a reduction along dim 1 creates a different reduction shape which
is applied 3 times. Here is what that looks like,</p>
<img alt="_images/sum1.png" class="align-center" src="_images/sum1.png" />
<p>The same approach can be applied in higher dimensions. If we want to sum
over one of the dimensions we just create the reduction shape and apply it,</p>
<img alt="_images/sum2.png" class="align-center" src="_images/sum2.png" />
<p>When you implement, think about enumerating over positions in the final
tensor, and then applying the reduction shape to get the indices over the
original tensor,</p>
<img alt="_images/implement.png" class="align-center" src="_images/implement.png" />
<p>Finally, there is a special case reduction where we reduce over the entire
tensor. You can think of this as creating a reduction shape over the full
tensor and then viewing the result as a scalar.</p>
<img alt="_images/sum.png" class="align-center" src="_images/sum.png" />
<p>In the next module, we will discuss efficient implementation of the
above operations.  For now, they can be implemented by slow but
correct loops over all elements in the input tensors. This approach
can be used to implement key tensor operations, without doing more
than implementing the above higher-order functions.</p>
</div>
</div>


              </div>
              
              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="broadcasting.html" title="previous page">Broadcasting</a>
    <a class='right-next' id="next-link" href="tensor.html" title="next page">Tensor Variables</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2020, Sasha Rush.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.0.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>