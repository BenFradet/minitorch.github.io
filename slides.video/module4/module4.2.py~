# + slideshow={"slide_type": "skip"}
from mt_diagrams.drawing import connect
from mt_diagrams.tensor_draw import color, draw_equation, matrix, matrix_op, t, image_matmul_full, image_matmul_simple, m
import chalk
chalk.set_svg_draw_height(400)
chalk.set_svg_height(200)
import numba
import minitorch
FastTensorBackend = minitorch.TensorBackend(minitorch.FastOps)
def tensor(x):
    return minitorch.tensor(x, backend=FastTensorBackend)

def rand(*shape):
    return minitorch.rand(shape, backend=FastTensorBackend)

# + [markdown] slideshow={"slide_type": "slide"}
# Module 4.2 - Shapes
# ===================================

# + [markdown] slideshow={"slide_type": "slide"}
# Convolution Forward
# --------------------
# ![](https://minitorch.github.io/figs/Conv/conv1d.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Computation
# -----------
# Output Values
# ```
#   output[0] = weight[0] * input[0] + weight[1] * input[1]  + weight[2] * input[2]
#   output[1] = weight[0] * input[1] + weight[1] * input[2]  + weight[2] * input[3]
#   output[2] = weight[0] * input[2] + weight[1] * input[3]  + weight[2] * input[4]
# ``` 

# + [markdown] slideshow={"slide_type": "slide"}
# Alternative View
# -----------------
# Unroll 

# + slideshow={"slide_type": "x"}
def unroll(input, T, K):
    out = [[input[i + k] if i + k < T else 0
            for k in range(K)]
           for i in range(T)]           
    return tensor(out)


# + [markdown] slideshow={"slide_type": "slide"}
# Alternative View
# -----------------
# Unroll 
# + slideshow={"slide_type": "x"}
input = tensor([1, 2, 3, 4, 5, 6])
K = 3
T = input.shape[0]
unrolled_input = unroll(input, T, K)
print(unrolled_input)

# + [markdown] slideshow={"slide_type": "slide"}
# Gradient
# ---------

# + slideshow={"slide_type": "x"}
class Conv:

    @staticmethod
    def backward(ctx, d):
        ...
        grad_input[2] = weight[0] * d[2] + weight[1] * d[1]  + weight[2] * d[0]
        ...

        
# + [markdown] slideshow={"slide_type": "slide"}
# Conv Back - Input
# ------------------

# Reverse the convolutional anchor

# ![](https://minitorch.github.io/figs/Conv/conv1dback.png)
#  

# + [markdown] slideshow={"slide_type": "slide"}
# Graphical Representation
# -------------------------
# ![](https://minitorch.github.io/figs/Conv/channels.png)



# + [markdown] slideshow={"slide_type": "slide"}
# Two Dimensional Convolution
# ----------------------------
# * Instead of line, now use box
# * Box is anchored at the top-left
# * Zip-reduce is over full box!

# + [markdown] slideshow={"slide_type": "slide"}
# Convolution
# -----------
# ![](https://minitorch.github.io/figs/Conv/conv.png)


# + [markdown] slideshow={"slide_type": "slide"}
# Quiz
# -----------
# Quiz

# + [markdown] slideshow={"slide_type": "slide"}
# 3D Convolution
# ===============


# + [markdown] slideshow={"slide_type": "slide"}
# 3D Convolution?
# ----------------
# * Yeah!
# * Several neat versions

# + [markdown] slideshow={"slide_type": "slide"}
# 3D Convolution Voxels
# ---------------------
# ![](https://minitorch.github.io/figs/3dconv.png)


# + [markdown] slideshow={"slide_type": "slide"}
# 3D Convolution Chemistry
# -------------------------
# ![](https://minitorch.github.io/figs/chem.gif)


# + [markdown] slideshow={"slide_type": "slide"}
# 3D Convolution Video
# -------------------------
# ![](https://minitorch.github.io/figs/video.jpeg)



# + [markdown] slideshow={"slide_type": "slide"}
# Pooling
# ========

# + [markdown] slideshow={"slide_type": "slide"}
# Challenge
# ---------
# * How do we look at bigger areas with convolutions?

# + [markdown] slideshow={"slide_type": "slide"}
# Pooling
# ----------
# * Adjusts the scale at each layer
# * Conv stays the same size, image "zooms" out


# + [markdown] slideshow={"slide_type": "slide"}
# 2D Pooling
# -----------
# ![](https://minitorch.github.io/figs/Conv/pool2d.png)
#            

# + [markdown] slideshow={"slide_type": "slide"}
# Goal
# ------
# * Early layers: Capture basic shapes
# * Middle layers: How these connect
# * Later layers: Full objects

# + [markdown] slideshow={"slide_type": "slide"}
# Example
# --------
# ![](https://minitorch.github.io/figs/vis.png)


# + [markdown] slideshow={"slide_type": "slide"}
# Issues
# ---------
# * Number of parameters scale with weight size
# * "Bigger" patterns require more ways to split data.

# + [markdown] slideshow={"slide_type": "slide"}
# Standard Reduction
# -------------------
# ![](https://minitorch.github.io/figs/Conv/pool1.png)
#   

# + [markdown] slideshow={"slide_type": "slide"}
# "Pooling"
# -----------
# Reduction applied to each region:

# ![](https://minitorch.github.io/figs/Conv/pool2.png)
#            

# + [markdown] slideshow={"slide_type": "slide"}
# Simple Implementation
# ----------------------

# * Ensure that it is contiguous
# * Use View to "fold" the tensor
#
# ![](https://minitorch.github.io/figs/Conv/pool3.png)

# + [markdown] slideshow={"slide_type": "slide"}
# Why does folding work?
# -----------------------
# * View requires "contiguous" tensor
# * View(4, 2) makes strides (2, 1)
# ![](https://minitorch.github.io/figs/Conv/pool3.png)


# + [markdown] slideshow={"slide_type": "slide"}
# Simple Implementation
# ----------------------

# * Reduce along created fold
# ![](https://minitorch.github.io/figs/Conv/pool4.png)


# + [markdown] slideshow={"slide_type": "slide"}
# 2D Pooling
# -----------
# * Need to isolate squares into a single dimension.
# * Tensor origami :)

# + [markdown] slideshow={"slide_type": "slide"}
# Exercise
# -----------
# * If I have a (10, 10) cube. How do I sum up neighboring rows?
# * Goal (5, 10) cube.

# + [markdown] slideshow={"slide_type": "slide"}
# Fast Implementations?
# ---------------------

# * If your reduce is on CUDA, can exploit small groups
# * I.e. Prefix sum for each group on one block.

# + [markdown] slideshow={"slide_type": "slide"}
# Gradient Flow
# --------------

# * Layers that are used get more updates
# * Gradient signals which aspect was important
# * Can have extra layers
