# ---
# jupyter:
#   jupytext:
#     cell_metadata_filter: slideshow,-all
#     custom_cell_magics: kql
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.14.1
#   kernelspec:
#     display_name: minitorch
#     language: python
#     name: minitorch
# ---

# %% slideshow={"slide_type": "skip"}
import math
from typing import Callable

import chalk

from minitorch import Module, Parameter

chalk.set_svg_height(300)

# %% [markdown] slideshow={"slide_type": "slide"}
#
# Module 0.2 - Models and Modules
# =============================================

# %% [markdown] slideshow={"slide_type": "slide"}
# Module 0.2
# ------------
#   Models and Modules


# %% [markdown] slideshow={"slide_type": "slide"}
# Class Note
# -------------
# * You need to link your GitHub account
# * Still several students with unlinked accounts

# %% [markdown] slideshow={"slide_type": "slide"}
# Review
# =========

# %% [markdown] slideshow={"slide_type": "slide"}
# Function Type
# ------------------------

# %% slideshow={"slide_type": "x"}
def add(a: float, b: float) -> float:
    return a + b


def mul(a: float, b: float) -> float:
    return a * b


v: Callable[[float, float], float] = add

# %% [markdown] slideshow={"slide_type": "slide"}
# # Functions as Arguments

# %% slideshow={"slide_type": "x"}
from typing import Callable


def combine3(
    fn: Callable[[float, float], float], a: float, b: float, c: float
) -> float:
    return fn(fn(a, b), c)


print(combine3(add, 1, 3, 5))
print(combine3(mul, 1, 3, 5))


# %% [markdown] slideshow={"slide_type": "slide"}
# Functional Python
# -----------------------
#
# Functions as Returns

# %% slideshow={"slide_type": "x"}
def combine3(
    fn: Callable[[float, float], float]
) -> Callable[[float, float, float], float]:
    def new_fn(a: float, b: float, c: float) -> float:
        return fn(fn(a, b), c)

    return new_fn


# %% slideshow={"slide_type": "x"}
add3: Callable[[float, float, float], float] = combine3(add)
mul3: Callable[[float, float, float], float] = combine3(mul)

print(add3(1, 3, 5))

# %% [markdown] slideshow={"slide_type": "slide"}
# Quiz
# ------


# %% [markdown] slideshow={"slide_type": "slide"}
# Outline
# ---------
# * Modules
# * Visualization
# * Datasets

# %% [markdown] slideshow={"slide_type": "slide"}
# Modules
# ===============

# %% [markdown] slideshow={"slide_type": "slide"}
#
# Model
# ------
# * Models: parameterized functions.
#   *  $m(x; \theta)$
#   *  $x \text{ - input}$
#   *  $m \text{ - model}$
#
# * Initial Focus:
#   *  $\theta \text{ - parameters}$

# %% [markdown] slideshow={"slide_type": "slide"}
#
# Parameters
# -----------
#
# * Anything learned is in the parameters.
# * Modern parameters sets are both:
#   * Large
#   * Complex


# %% [markdown] slideshow={"slide_type": "slide"}
# Growth in Parameter Size
# --------------------------
#  <img src="https://developer-blogs.nvidia.com/wp-content/uploads/2021/10/Model-Size-Chart.png" >
#


# %% [markdown] slideshow={"slide_type": "slide"}
# Complexity
# ---------------------
#
# Inception - Table of precise sizes
#
# ![](images/inception_v3.png)


# %% [markdown] slideshow={"slide_type": "slide"}
# Specifying Parameters
# -----------------------
# * Datastructures to specify parameters
# * Requirements
#   * Independent of implementation
#   * Compositional


# %% [markdown] slideshow={"slide_type": "slide"}
#
# Module Trees
# ----------------
# * Each Module owns a set of parameters
# * Each Module owns a set of submodules

# %% [markdown] slideshow={"slide_type": "slide"}
# Module Trees
# ----------------
# Benefits
# * Can extract all parameters without knowing about Modules
# * Can use mix and match Modules for different tasks
#
# Downsides
# * Verbose, repeats some functionality of declaration and use.


# %% [markdown] slideshow={"slide_type": "slide"}
# Module Storage
# ---------------
# Stores three things:
#    *  Parameters
#    *  Submodules
#    *  Generic Python attributes

# %% [markdown] slideshow={"slide_type": "slide"}
# Module Example
# ----------------

# %% slideshow={"slide_type": "x"}
from minitorch import Module, Parameter

class OtherModule(Module):
    def __init__(self):
        # Must initialize the super class!
        super().__init__()
        self.uncool_parameter = Parameter(60)

class MyModule(Module):
    def __init__(self):
        # Must initialize the super class!
        super().__init__()

        # Type 1, a parameter.
        self.parameter1 = Parameter(15)
        self.cool_parameter = Parameter(50)

        # Type 2, user data
        self.data = 25

        # Type 3. another Module
        self.sub_module_a = OtherModule()
        self.sub_module_b = OtherModule()


# %% [markdown] slideshow={"slide_type": "slide"}
# Parameters
# ----------------
#    * Everything that is learned in the model
#    * Controlled and changed outside the class

# %% [markdown] slideshow={"slide_type": "slide"}
# Submodules
# ---------------
#    * Other modules that are called
#    * Store their own parameters and submodules
#    * Together forms a tree

# %% [markdown] slideshow={"slide_type": "slide"}
# Everything Else
# ---------------
#    * Modules act mostly like standard python objects
#    * You can have additional information stored

# %% [markdown] slideshow={"slide_type": "slide"}
# Module Example
# ----------------

# %% slideshow={"slide_type": "x"}
MyModule().named_parameters()


# %% [markdown] slideshow={"slide_type": "slide"}
#
# Extended Example
# ----------------

# %% slideshow={"slide_type": "x"}
class Module2(Module):
    def __init__(self):
        super().__init__()
        self.p2 = Parameter(10)

class Module3(Module):
    def __init__(self):
        super().__init__()
        self.c = Module4()

class Module4(Module):
    def __init__(self):
        super().__init__()
        self.p3 = Parameter(15)


# %% [markdown] slideshow={"slide_type": "slide"}
#
# Extended Example
# ----------------

# %% slideshow={"slide_type": "x"}
class Module1(Module):
    def __init__(self):
        super().__init__()
        self.p1 = Parameter(5)
        self.a = Module2()
        self.b = Module3()

Module1().named_parameters()


# %% [markdown] slideshow={"slide_type": "slide"}
# How does this work?
# --------------------
# * Internally `Module` spies to find `Parameter` and `Module` objects
# * A list is stored internally.
# * Implemented through Python magic methods


# %% [markdown] slideshow={"slide_type": "slide"}
# Detail: Magic Methods
# ----------------------
# * Any method that starts and ends with `__`
# * Used to override default behavior of the language.
# * We will use for many things, including operator overloading

# %% [markdown] slideshow={"slide_type": "slide"}
# Interception Code
# ------------------
# Module construction

# %% slideshow={"slide_type": "x"}
class MyModule(Module):
    def __setattr__(self, key, val):
        if isinstance(val, Parameter):
            self.__dict__["_parameters"][key] = val
        elif isinstance(val, Module):
            self.__dict__["_modules"][key] = val
        else:
            super().__setattr__(key, val)


# %% [markdown] slideshow={"slide_type": "slide"}
# Parameter Naming
# -----------------
# * Every parameter in a model has a unique name.
# * Naming is determined by walking the tree.
# * Names are prefixed by the path from the root.

# %% [markdown] slideshow={"slide_type": "slide"}
# Module Naming
# ---------------
#
# ![](https://minitorch.github.io/figs/Module/module.png)

# %% [markdown] slideshow={"slide_type": "slide"}
#
# Other Module Metadata
# ----------------------
# * Other information can be communicated through the tree.
# * Common example: Is the model in train or test mode?


# %% [markdown] slideshow={"slide_type": "slide"}
#
# Homework Note
# --------------
# * Must be recursive implementation
# * Have to walk the full tree
# * (Companies love this as an interview question!)

# %% [markdown] slideshow={"slide_type": "slide"}
#
# Real World Examples
# ---------------------
#
# Code from [GPT-2](https://huggingface.co/transformers/_modules/transformers/modeling_gpt2.html)

# %% slideshow={"slide_type": "x"}

from torch import nn

class Block(nn.Module):
    def __init__(self, n_ctx, config, scale=False):
        super().__init__()
        hidden_size = config.n_embd
        inner_dim = config.n_inner if config.n_inner is not None else 4 * hidden_size
        self.ln_1 = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)
        self.attn = Attention(hidden_size, n_ctx, config, scale)
        self.ln_2 = nn.LayerNorm(hidden_size, eps=config.layer_norm_epsilon)
        if config.add_cross_attention:
            self.crossattention = Attention(
                hidden_size, n_ctx, config, scale, is_cross_attention=True
            )
            self.ln_cross_attn = nn.LayerNorm(
                hidden_size, eps=config.layer_norm_epsilon
            )
        self.mlp = MLP(inner_dim, config)


# %% [markdown]
# ## GPT 2

# %% [markdown] slideshow={"slide_type": "slide"}
# Real World Examples
# ---------------------
#
# Block from [Inception](https://pytorch.org/vision/stable/_modules/torchvision/models/inception.html)

# %% slideshow={"slide_type": "x"}
class Inception3(nn.Module):
    def __init__(
        self,
        num_classes=1000,
        aux_logits=True,
        transform_input=False,
        inception_blocks=None,
        init_weights=None,
    ):
        super(Inception3, self).__init__()
        ...
        self.aux_logits = aux_logits
        self.transform_input = transform_input
        self.Conv2d_1a_3x3 = conv_block(3, 32, kernel_size=3, stride=2)
        self.Conv2d_2a_3x3 = conv_block(32, 32, kernel_size=3)
        self.Conv2d_2b_3x3 = conv_block(32, 64, kernel_size=3, padding=1)
        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)
        self.Conv2d_3b_1x1 = conv_block(64, 80, kernel_size=1)
        self.Conv2d_4a_3x3 = conv_block(80, 192, kernel_size=3)
        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)
        self.Mixed_5b = inception_a(192, pool_features=32)
        self.Mixed_5c = inception_a(256, pool_features=64)
        self.Mixed_5d = inception_a(288, pool_features=64)
        self.Mixed_6a = inception_b(288)
        self.Mixed_6b = inception_c(768, channels_7x7=128)
        self.Mixed_6c = inception_c(768, channels_7x7=160)
        self.Mixed_6d = inception_c(768, channels_7x7=160)
        self.Mixed_6e = inception_c(768, channels_7x7=192)
        if aux_logits:
            self.AuxLogits = inception_aux(768, num_classes)
        self.Mixed_7a = inception_d(768)
        self.Mixed_7b = inception_e(1280)
        self.Mixed_7c = inception_e(2048)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.dropout = nn.Dropout()
        self.fc = nn.Linear(2048, num_classes)


# %% [markdown] slideshow={"slide_type": "slide"}
# Visualization
# ===============

# %% [markdown] slideshow={"slide_type": "slide"}
# Main Idea
# ----------
#
# * Show properties of your model as you code
# * See real time graphs as you train models
# * Make convincing figures of your full system

# %% [markdown] slideshow={"slide_type": "slide"}
# Library: Streamlit
# --------------------
#
# Easy to use Python GUI
#
# ```bash
# >>> streamlit run app.py -- 0
# ```

# %% [markdown] slideshow={"slide_type": "slide"}
# Code Snippet
# -------------
# Streamlit windows
# ```python
# import streamlit as st
# st.write("## Sandbox for Model Training")
#     ...
# st.plotly_chart(fig)
# ```

# %% [markdown] slideshow={"slide_type": "slide"}
# Gotchas
# ---------------------
# * Changes to the visualization code will autoupdate
# * Changes to the library will not autoupdate

# %% [markdown] slideshow={"slide_type": "slide"}
# Other Options
# ---------------------
#
# Many other ML tailored options
#
# * Tensorboard
#
# * Hosted services: Weights and Biases, Comet

# %% [markdown] slideshow={"slide_type": "slide"}
# Datasets
# =========

# %% [markdown] slideshow={"slide_type": "slide"}
# Sneak Preview
# ---------------
# * Task 0.5: Intro to our first ML problem
# * Basic separation of points on a graph
# * Manual classifier

# %% [markdown] slideshow={"slide_type": "slide"}
# Datasets
# ----------
#
# * Simple
# * Diag
# * Split
# * Xor

# %% [markdown] slideshow={"slide_type": "slide"}
# Parameter Knobs
# ---------------
#
# * W1
# * W2
# * Bias

# %% [markdown] slideshow={"slide_type": "slide"}
# Sneak Preview
# ---------------
#
#    [Playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.91939&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false&learningRate_hide=true&regularizationRate_hide=true&batchSize_hide=true&noise_hide=true&discretize_hide=true&regularization_hide=true&activation_hide=true)


# %% [markdown] slideshow={"slide_type": "slide"}
# Q&A
# -------
