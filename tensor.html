

<!DOCTYPE html>
<html class="writer-html5" lang="english" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tensor Variables &mdash; MiniTorch 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Broadcasting" href="broadcasting.html" />
    <link rel="prev" title="Operations" href="tensorops.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> MiniTorch
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="setup.html">Workspace Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="module0.html">Module 0 - Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="module1.html">Module 1 - Auto-Differentiation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="module2.html">Module 2 - Tensors</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="tensordata.html">Tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensorops.html">Operations</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Tensor Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="broadcasting.html">Broadcasting</a></li>
<li class="toctree-l2"><a class="reference internal" href="module2.html#tasks">Tasks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="module3.html">Module 3 - Efficiency</a></li>
<li class="toctree-l1"><a class="reference internal" href="module4.html">Module 4 - Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlprimer.html">ML Primer</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">MiniTorch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="module2.html">Module 2 - Tensors</a> &raquo;</li>
        
      <li>Tensor Variables</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/tensor.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tensor-variables">
<h1>Tensor Variables<a class="headerlink" href="#tensor-variables" title="Permalink to this headline">Â¶</a></h1>
<p>Next we consider autodifferentiation in the tensor framework. We have
now moved from scalars and derivatives to vector, matrices and
tensors.  This means <cite>multivariate calculus</cite> and can bring into play
somewhat scary terminology. However, most of what we actually need to
do will not require complicated terminology or much technical math. In
fact, excepting some name changes, we have already build almost
everything we need in <a class="reference internal" href="module1.html"><span class="doc">Module 1 - Auto-Differentiation</span></a>.</p>
<p>The key idea is that just as we had <cite>Scalar</cite> and <cite>ScalarFunction</cite>, we need to
construct a <cite>Tensor</cite> and <cite>TensorFunction</cite> (which we just call <cite>Function</cite>).
These new objects behave very similar to their counterparts:</p>
<ol class="loweralpha simple">
<li><p>Tensor's cannot be operated on directly, but need to be transformed through a Function.</p></li>
<li><p>Function's must implement both a forward method and also a backward method.</p></li>
<li><p>These transformations are tracked, which allow backpropagation through the chain-rule.</p></li>
</ol>
<p>All of this machinery should work out of the box.</p>
<p>The main new terminology to know is <cite>gradient</cite>. Just as a tensor is a
multidimensional array of scalars, a gradient is a multidimensional
array of derivatives for these scalars.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assignment 1 notation</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">derivative</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">derivative</span><span class="p">,</span> <span class="n">c</span><span class="o">.</span><span class="n">derivative</span><span class="p">)</span>


<span class="c1"># Assignment 2 notation</span>
<span class="n">tensor1</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">tensor1</span><span class="p">)</span>
<span class="n">out</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="c1"># shape (3,)</span>
<span class="n">tensor1</span><span class="o">.</span><span class="n">grad</span>
</pre></div>
</div>
<p>The gradient of <cite>tensor1</cite> is a tensor that holds the derivatives of
each of its values. The other place that gradients come into play is
that backward no longer takes <span class="math notranslate nohighlight">\(d_{out}\)</span> as an argument, but now
takes <span class="math notranslate nohighlight">\(grad_{out}\)</span>. Again, this is just a tensor of all the
<span class="math notranslate nohighlight">\(d_{out}\)</span> corresponding to the output tensor.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>(You will find lots of different notation for
gradients and multivariate terminology. For this assignment, I ask
that you ignore it and stick to everything you know about derivatives.
It turns out that you can do must of machine learning without ever
thinking in higher dimensions.)</p>
</div>
<p>If you think about a gradient and <span class="math notranslate nohighlight">\(grad_{out}\)</span> in this way (tensor of derivatives :math:<a href="#id1"><span class="problematic" id="id2">`</span></a>d_{out}),
you can then see how we can easily compute the gradient of each tensor
operations be using univariate rules.</p>
<ol class="arabic simple">
<li><p><strong>map</strong>. Given a tensor, map applies a univariate operation to each scalar
position individually. For a scalar <span class="math notranslate nohighlight">\(x\)</span>, it computes
<span class="math notranslate nohighlight">\(g(x)\)</span>.  Therefore, from assignment 1, we know that the
derivative <span class="math notranslate nohighlight">\(f(g(x))\)</span> is equal to <span class="math notranslate nohighlight">\(g'(x) \times d_{out}\)</span>. This
means to compute the backward gradient, we only need to compute the
derivative for each position and apply a <cite>mul</cite> map.</p></li>
</ol>
<img alt="_images/map back.png" class="align-center" src="_images/map back.png" />
<ol class="arabic simple" start="2">
<li><p><strong>zip</strong>. Given two tensors, zip applies a fixed operation to each
scalar position as a pair. For two scalars <span class="math notranslate nohighlight">\(x\)</span> and
<span class="math notranslate nohighlight">\(y\)</span>, it computes <span class="math notranslate nohighlight">\(g(x, y)\)</span>.  Therefore, from assignment
1, we know that the derivative <span class="math notranslate nohighlight">\(f(g(x, y))\)</span> is equal to
<span class="math notranslate nohighlight">\(g_x'(x, y) \times d_{out}\)</span> and <span class="math notranslate nohighlight">\(g_y'(x, y) \times d_{out}\)</span>. This
means to compute the gradient, we only need to compute the
derivative for each position and <cite>mul</cite> map.</p></li>
</ol>
<img alt="_images/zip back.png" class="align-center" src="_images/zip back.png" />
<ol class="arabic simple" start="3">
<li><p><strong>reduce</strong>. Given a tensor, reduce applies a fixed aggregation
operation to one dimension. For simplicity, let's consider sum-based
reductions.  For scalars <span class="math notranslate nohighlight">\(x_1\)</span> to <span class="math notranslate nohighlight">\(x_n\)</span>, it computes
<span class="math notranslate nohighlight">\(x_1 + x_2 + \ldots\)</span>.  For any <span class="math notranslate nohighlight">\(x\)</span> value this
yields 1. Therefore, the derivative for any position is simply the
derivative passed backward <span class="math notranslate nohighlight">\(d_{out}\)</span>. This means to compute the
gradient, we only need to send the derivative to each
position. (For other reduce operations such as <cite>product</cite>, you get
different expansions, but these can be calculated just by taking
derivatives).</p></li>
</ol>
<img alt="_images/reduce back.png" class="align-center" src="_images/reduce back.png" />
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="broadcasting.html" class="btn btn-neutral float-right" title="Broadcasting" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="tensorops.html" class="btn btn-neutral float-left" title="Operations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Sasha Rush

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>