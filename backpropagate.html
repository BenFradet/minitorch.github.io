
<!DOCTYPE html>

<html lang="english">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Backpropagation &#8212; MiniTorch 0.1 documentation</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/css/blank.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <link rel="stylesheet" type="text/css" href="_static/thebelab.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/thebelab-helper.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Tensors" href="module2.html" />
    <link rel="prev" title="Autodifferentiation" href="chainrule.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="english">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="index.html">
  <img src="_static/minitorch.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="setup.html">
  Setup
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="mlprimer.html">
  ML Primer
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module0.html">
  Fundamentals
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="module1.html">
  Autodiff
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module2.html">
  Tensors
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module3.html">
  Efficiency
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="module4.html">
  Networks
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/minitorch/" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://twitter.com/srush_nlp" rel="noopener" target="_blank" title="Twitter">
            <span><i class="fab fa-twitter-square"></i></span>
            <label class="sr-only">Twitter</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p>
 <span class="caption-text">
  Guides
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="derivative.html">
   Derivatives
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="scalar.html">
   Tracking Variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chainrule.html">
   Autodifferentiation
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Backpropagation
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running-example">
   Running Example
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#topological-sort">
   Topological Sort
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#backprop">
   Backprop
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algorithm">
   Algorithm
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="backpropagation">
<h1>Backpropagation<a class="headerlink" href="#backpropagation" title="Permalink to this headline">¶</a></h1>
<p>The <cite>backward</cite> function tells us how to compute the derivative of one
operation.  The chain rule tells us how to compute the derivative of two
sequential operations.  In this section, we show how to use these to
compute the derivative for an arbitrary series of operations.</p>
<p>Practically this looks like re-running our graph in reverse order from
right-to-left. However, we need to ensure that we do this in the
correct order. The key implementation challenge of backpropagation is
to make sure that we process each node in the correct order, i.e.
we have first processed every node that uses a Variable before that
varible itself.</p>
<section id="running-example">
<h2>Running Example<a class="headerlink" href="#running-example" title="Permalink to this headline">¶</a></h2>
<p>Assume we have Variables <span class="math notranslate nohighlight">\(x,y\)</span> and a Function <span class="math notranslate nohighlight">\(h(x,y)\)</span>. We want
to compute the derivatives <span class="math notranslate nohighlight">\(h'_x(x, y)\)</span> and <span class="math notranslate nohighlight">\(h'_y(x, y)\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray*}
h(x, y) &amp;=&amp; \log(z) + \exp(z) \\
   \text{where} &amp;&amp; z = x \times y \\
\end{eqnarray*}\end{split}\]</div>
<p>We assume x, +, log, and exp are all implemented as ScalarFunctions which
can store
their history. This means that the final output Variable has constructed a
graph of its history
that looks like this:</p>
<img alt="_images/backprop1.png" class="align-center" src="_images/backprop1.png" />
<p>Here, starting from the left, the first arrows represent inputs
<span class="math notranslate nohighlight">\(x,y\)</span>, the left node outputs <span class="math notranslate nohighlight">\(z\)</span>, the top node
<span class="math notranslate nohighlight">\(\log(z)\)</span>, the bottom node <span class="math notranslate nohighlight">\(\exp(z)\)</span> and the final right
node <span class="math notranslate nohighlight">\(h(x, y)\)</span>. Forward computation proceeds left-to-right.</p>
<p>The chain rule tells us the rule for propagating the derivatives. We
need to apply the <cite>backward</cite> functions right-to-left until we reach
the initial Variables <span class="math notranslate nohighlight">\(x,y\)</span>, i.e. the <cite>leaf</cite> Variables.</p>
<p>We could just apply this rule randomly and process each nodes as they
come aggregating the resulted values. However this can be quite  inefficient.
For instance, consider an order of: right, top, left, bottom. While this
processes each node, some derivatives do not reach their original Variables. To
make this work we would need an order of: right, top, left, bottom, left.</p>
</section>
<section id="topological-sort">
<h2>Topological Sort<a class="headerlink" href="#topological-sort" title="Permalink to this headline">¶</a></h2>
<p>To handle this issue, we will process the nodes in <cite>topological
order</cite>.  We first note that our graph is directed and that acyclic.
Directionality comes from the <cite>backward</cite> function, and the lack of
cycles is a consequence of the choice that every Function must create a
new variable.</p>
<p>The topological ordering of a directed acyclic graph is an ordering
that ensures no node is processed after its ancestor, e.g. in our
example that the left node cannot be processed before the top or
bottom node. The ordering may not be unique, and it does not tell us
whether to process the top or bottom node first.</p>
<p>There are several easy-to-implement algorithms for topological sorting.
As graph algorithms are beyond the scope of this document, we recommend
using the depth-first search algorithm described in pseudocode section of
<a class="reference external" href="http://wikipedia.org/wiki/Topological_sorting">Topological Sorting</a>.</p>
<dl class="py function">
<dt id="minitorch.topological_sort">
<code class="sig-prename descclassname">minitorch.</code><code class="sig-name descname">topological_sort</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">variable</span></em><span class="sig-paren">)</span><a class="headerlink" href="#minitorch.topological_sort" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the topological order of the computation graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>variable</strong> (<a class="reference internal" href="scalar.html#minitorch.Variable" title="minitorch.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code></a>) -- The right-most variable</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="simple">
<dt>Non-constant Variables in topological order</dt><dd><p>starting from the right.</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>list of Variables</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="backprop">
<h2>Backprop<a class="headerlink" href="#backprop" title="Permalink to this headline">¶</a></h2>
<p>Once we have the order defined, we process each node one at a time.
We start the right node (<span class="math notranslate nohighlight">\(h(x,y)\)</span>) with red arrow
in the graph below. The starting derivative is an argument given to us.</p>
<img alt="_images/backprop2.png" class="align-center" src="_images/backprop2.png" />
<p>We then process the Function with the chain rule. This calls
<cite>backward</cite> of +, and gives the derivative for the two red Variables
(which correspond to <span class="math notranslate nohighlight">\(\log(z), \exp(z)\)</span> from the <cite>forward</cite>
pass). You need to track these intermediate red derivative values in a
dictionary.</p>
<img alt="_images/backprop3.png" class="align-center" src="_images/backprop3.png" />
<p>Let us assume the next Variable in the order is the top node. We have
just computed and stored the necessary derivative <span class="math notranslate nohighlight">\(d_{out}\)</span>, so
we can apply the chain rule. This produces a new derivative (corresponding to
<span class="math notranslate nohighlight">\(z\)</span>: left red arrow below) for us to store.</p>
<img alt="_images/backprop4.png" class="align-center" src="_images/backprop4.png" />
<p>The next Variable in the order is the bottom node. Here we have an
interesting result. We have a new arrow, but it corresponds to the
same Variable (<span class="math notranslate nohighlight">\(z\)</span>) that we just computed. It is is a useful
exercise to show that as a consequence of the two argument chain rule
that the derivative for this Variable is the sum of each of these
derivatives. Practically this means just adding it to your dictionary.</p>
<img alt="_images/backprop5.png" class="align-center" src="_images/backprop5.png" />
<p>After working on this Variable, at this point, all that is left in the
is our input leaf Variables.</p>
<img alt="_images/backprop6.png" class="align-center" src="_images/backprop6.png" />
<p>When we reach the leaf Variables in our order, for example
<span class="math notranslate nohighlight">\(x\)</span>, we store the derivative with that Variable.
Since each step of this process is an application of the chain rule, we can
show that this final value
is <span class="math notranslate nohighlight">\(h'_x(x, y)\)</span>. The next and last step is to compute <span class="math notranslate nohighlight">\(h'_y(x, y)\)</span>.</p>
<img alt="_images/backprop7.png" class="align-center" src="_images/backprop7.png" />
<p>By convention, if <span class="math notranslate nohighlight">\(x, y\)</span> are instances of  <a class="reference internal" href="scalar.html#minitorch.Variable" title="minitorch.Variable"><code class="xref py py-class docutils literal notranslate"><span class="pre">minitorch.Variable</span></code></a>,
their derivatives are stored as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">derivative</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">derivative</span>
</pre></div>
</div>
</section>
<section id="algorithm">
<h2>Algorithm<a class="headerlink" href="#algorithm" title="Permalink to this headline">¶</a></h2>
<p>As illustrated in the graph for the above example, each of the red
arrows represents a constructed derivative which eventually passed to
<span class="math notranslate nohighlight">\(d_{out}\)</span> in the chain rule.  Starting from the rightmost arrow,
which is passed in as an argument, backpropagate should run the
following algorithm:</p>
<ol class="arabic simple" start="0">
<li><p>Call topological sort to get an ordered queue</p></li>
<li><p>Create a dictionary of Variables and current derivatives</p></li>
<li><p>For each node in backward order, pull a completed Variable and
derivative from the queue:</p>
<ol class="loweralpha simple">
<li><p>if the Variable is a leaf, add its final derivative (<cite>accumulate_derivative</cite>)
and loop to (1)</p></li>
<li><p>if the Variable is not a leaf,</p>
<ol class="arabic simple">
<li><p>call <cite>.backprop_step</cite> on the last function that created it with
derivative as <span class="math notranslate nohighlight">\(d_{out}\)</span></p></li>
<li><p>loop through all the Variables+derivative produced by the chain
rule</p></li>
<li><p>accumulate derivatives for the Variable in a dictionary
(check <cite>.unique_id</cite>)</p></li>
</ol>
</li>
</ol>
</li>
</ol>
<p>Final note: only leaf Variables should ever have non-None
<cite>.derivative</cite> value. All intermediate Variables should only keep
their current derivative values in the dictionary. This is a
bit annoying, but it follows the behavior of PyTorch.</p>
</section>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="chainrule.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Autodifferentiation</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="module2.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tensors</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Sasha Rush.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>